{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db838a44-10b7-4d56-983f-4e2c059496cd",
   "metadata": {},
   "source": [
    "# IE 582 Statistical Learning for Data Mining\n",
    "### Part 1: Project Data Preparation\n",
    "**Date:** *13-01-2025*  \n",
    "- **Name:** *Fatih Mehmet Yılmaz*\n",
    "    - **School Number:** *2024702054*  \n",
    "- **Name:** *Yusuf Sina Öztürk*\n",
    "    - **School Number:** *2023702075*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ceed3d",
   "metadata": {},
   "source": [
    "In this part, we ***prepared the data*** aligned with the results that resulted from the ***exploratory data analysis.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a31c8-d9bf-4fb7-9557-d24d4e397139",
   "metadata": {},
   "source": [
    "### 0. Setup\n",
    "- Need to import all libraries where it will be used in different parts of the project.\n",
    "- Read provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682aff89-81a4-43c7-a099-3f45075349b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T15:09:19.862131Z",
     "iopub.status.busy": "2025-01-04T15:09:19.861505Z",
     "iopub.status.idle": "2025-01-04T15:09:30.289640Z",
     "shell.execute_reply": "2025-01-04T15:09:30.289051Z",
     "shell.execute_reply.started": "2025-01-04T15:09:19.862108Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.11/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "from ydata_profiling import ProfileReport\n",
    "from ydata_profiling.utils.cache import cache_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ca9485-ff31-415e-8f77-424286041487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T15:09:30.291193Z",
     "iopub.status.busy": "2025-01-04T15:09:30.290829Z",
     "iopub.status.idle": "2025-01-04T15:09:30.959596Z",
     "shell.execute_reply": "2025-01-04T15:09:30.958997Z",
     "shell.execute_reply.started": "2025-01-04T15:09:30.291173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "match_data = pd.read_csv('match_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bb53d4-4f04-4e86-bee8-5a3c2aed0880",
   "metadata": {},
   "source": [
    "### 1. Preparation of Data\n",
    "- First thing first, we deleted the rows that shouldn't be used in any anaylsis or training set. `suspended` and `stopped` columns in the set shows us which columns are not usable.\n",
    "    - For this reason, we should get rid of 7.8k rows that has `suspended` and 4.1k rows that has `stopped` status.\n",
    "    - After that, we got final of 56.1 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26c88d3e-78da-43ce-af25-75f0a5aa848f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:02:55.338583Z",
     "iopub.status.busy": "2024-12-17T19:02:55.337868Z",
     "iopub.status.idle": "2024-12-17T19:02:55.349578Z",
     "shell.execute_reply": "2024-12-17T19:02:55.348883Z",
     "shell.execute_reply.started": "2024-12-17T19:02:55.338553Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7817"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(match_data[match_data[\"suspended\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba4cdd74-c932-4cb8-9509-ee3c47ced14d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:02:56.558300Z",
     "iopub.status.busy": "2024-12-17T19:02:56.557557Z",
     "iopub.status.idle": "2024-12-17T19:02:56.566558Z",
     "shell.execute_reply": "2024-12-17T19:02:56.565851Z",
     "shell.execute_reply.started": "2024-12-17T19:02:56.558261Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4115"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(match_data[match_data[\"stopped\"] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b3c84bb8-3c8f-4d25-9b7f-8902572c7bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:02:57.165949Z",
     "iopub.status.busy": "2024-12-17T19:02:57.165232Z",
     "iopub.status.idle": "2024-12-17T19:02:57.217046Z",
     "shell.execute_reply": "2024-12-17T19:02:57.216354Z",
     "shell.execute_reply.started": "2024-12-17T19:02:57.165922Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56127"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_data = match_data[(match_data['stopped'] == False) & (match_data['suspended'] == False)]\n",
    "match_data = match_data.drop(columns=['stopped', 'suspended'])\n",
    "len(match_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078840a5-e687-476f-9034-f3039b7a6386",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1 Explatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689c798-8258-4a6c-b619-52e602816164",
   "metadata": {
    "tags": []
   },
   "source": [
    "- In order to check what is the properties of my dataset, we have used compact `ydata_profiling` library to check each column of my set with respect to their statistical values.\n",
    "\n",
    "- The function that used below created an HTML file, it is also **included in repository.**;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98f2f5d4-40a6-4980-bbbb-c5b352358bb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:12:52.179199Z",
     "iopub.status.busy": "2024-12-15T14:12:52.178653Z",
     "iopub.status.idle": "2024-12-15T14:13:28.718935Z",
     "shell.execute_reply": "2024-12-15T14:13:28.718156Z",
     "shell.execute_reply.started": "2024-12-15T14:12:52.179173Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c48f5eb3354440b57753856dfd0d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3614eb4f25c545c488e8ee5ec353826d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0faa76a7eac4491792516c3cbbedfd19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec53f4ca500468fa002f08fb9fb518a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 35.6 s, total: 1min 36s\n",
      "Wall time: 36.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "report = ProfileReport(match_data, title=\"HW2_EDA\", minimal=True)\n",
    "report.to_file(\"HW2_EDA.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e973997-83fa-44e1-9a2a-447b03e319ab",
   "metadata": {},
   "source": [
    "#### 1.2 Actions taken based on exploratory data analysis report\n",
    "\n",
    "- There is `ticking` named feature on dataset which is constant in all set. Also this unuseful feature is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c7e24332-3f8d-4b26-88d5-be10fb817c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:03:01.553155Z",
     "iopub.status.busy": "2024-12-17T19:03:01.552587Z",
     "iopub.status.idle": "2024-12-17T19:03:01.577900Z",
     "shell.execute_reply": "2024-12-17T19:03:01.577119Z",
     "shell.execute_reply.started": "2024-12-17T19:03:01.553122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "match_data = match_data.drop(columns=['ticking'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ad785-b149-407c-bc8f-bb19ce259352",
   "metadata": {},
   "source": [
    "**1.3 Comments and approaches for actions**\n",
    "\n",
    "- With EDA, we also captured with high percentage zero warning and missing values warning occured in dataset.\n",
    "\n",
    "\n",
    "  - For missing values, we should do imputation with linear interpolation.\n",
    "  \n",
    "  \n",
    "  - For zero values, we will check whether this zero is from start of the match or it is missinformation. For misinformed values, we need to apply also linear interpolation. \n",
    "  \n",
    "  \n",
    "      - After checking all distributions and some of the instances, there is no misinformation on zero valued instances.\n",
    "  \n",
    "  \n",
    "  - Percentage features has close to normal distribution, and seems there are misinformed values because 0 and 100 % are not fitted well on the histogram. \n",
    "  \n",
    "  \n",
    "      - Figured that out those are clearly the firts seconds of the match. That is why it is alright to keep it like that.\n",
    "  \n",
    "  \n",
    "  - For text features, we applied one-code encoding to make them binary, in order to let ML models learn a bit better. \n",
    "  \n",
    "  \n",
    "      - Only `name` feature of the oppenent teams are not encoded because it is more like the same as `fixture_id`. If we try to apply league based different models, or add league dimension into dataset, we could apply it on those sophisticated attemps . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6020bdd4-1f22-49bd-8a3a-e8a1db2e7acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:03:02.285972Z",
     "iopub.status.busy": "2024-12-17T19:03:02.285249Z",
     "iopub.status.idle": "2024-12-17T19:03:02.398463Z",
     "shell.execute_reply": "2024-12-17T19:03:02.397662Z",
     "shell.execute_reply.started": "2024-12-17T19:03:02.285943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In order to sort data set, need to convert types Date Time features \n",
    "datetime_columns = ['current_time', 'half_start_datetime', 'match_start_datetime', 'latest_bookmaker_update']\n",
    "match_data[datetime_columns] = match_data[datetime_columns].apply(pd.to_datetime)\n",
    "\n",
    "match_data = match_data.sort_values(by=['fixture_id', 'halftime', 'current_time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d3740767-7c52-4f00-b02d-b4db778dad8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:03:02.841674Z",
     "iopub.status.busy": "2024-12-17T19:03:02.840974Z",
     "iopub.status.idle": "2024-12-17T19:03:02.881864Z",
     "shell.execute_reply": "2024-12-17T19:03:02.881106Z",
     "shell.execute_reply.started": "2024-12-17T19:03:02.841624Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group features that should implemented different type of imputations\n",
    "# Features that needs to impute\n",
    "missing_features = match_data.columns[match_data.isnull().any()].tolist()\n",
    "\n",
    "percentage_features = [\n",
    "    \"Successful Passes Percentage - away\", \n",
    "    \"Successful Passes Percentage - home\", \n",
    "    \"Ball Possession % - away\", \n",
    "    \"Ball Possession % - home\"\n",
    "]\n",
    "text_feature = [\"current_state\"]\n",
    "\n",
    "integer_missing_features = set(missing_features) - set(percentage_features + text_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5570bc54-01a8-463e-b1bb-88cb19c8aceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:03:03.207364Z",
     "iopub.status.busy": "2024-12-17T19:03:03.206777Z",
     "iopub.status.idle": "2024-12-17T19:03:03.231269Z",
     "shell.execute_reply": "2024-12-17T19:03:03.230532Z",
     "shell.execute_reply.started": "2024-12-17T19:03:03.207336Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imputed Version of Dataset\n",
    "match_data_imputed = match_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55558613-1df8-4d70-8762-751eabc23669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:03:03.620479Z",
     "iopub.status.busy": "2024-12-17T19:03:03.619791Z",
     "iopub.status.idle": "2024-12-17T19:07:07.125016Z",
     "shell.execute_reply": "2024-12-17T19:07:07.124071Z",
     "shell.execute_reply.started": "2024-12-17T19:03:03.620450Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imputation for Integer Type Features\n",
    "for fixture_id, group in match_data.groupby('fixture_id'):\n",
    "    group = group.sort_values('current_time')\n",
    "\n",
    "    for feature in integer_missing_features:\n",
    "        missing_indices = group[group[feature].isna()].index\n",
    "\n",
    "        for idx in missing_indices:\n",
    "            valid_before = group.loc[:idx, feature].dropna()\n",
    "            lower_bound = valid_before.iloc[-1] if not valid_before.empty else pd.NA\n",
    "            lower_time = group.loc[valid_before.index[-1], 'current_time'] if not valid_before.empty else group.loc[idx, 'current_time']\n",
    "\n",
    "            valid_after = group.loc[idx:, feature].dropna()\n",
    "            upper_bound = valid_after.iloc[0] if not valid_after.empty else pd.NA\n",
    "            upper_time = group.loc[valid_after.index[0], 'current_time'] if not valid_after.empty else group.loc[idx, 'current_time']\n",
    "\n",
    "            if pd.isna(group.at[idx, feature]):\n",
    "                if pd.isna(lower_bound) == True & pd.isna(upper_bound) == True:\n",
    "                    continue\n",
    "                elif pd.isna(lower_bound):\n",
    "                    group.at[idx, feature] = 0\n",
    "                elif pd.isna(upper_bound):\n",
    "                    group.at[idx, feature] = lower_bound\n",
    "                else:\n",
    "                    time_diff = (upper_time - lower_time).total_seconds()\n",
    "                    value_diff = upper_bound - lower_bound\n",
    "                    time_diff_missing = (group.loc[idx, 'current_time'] - lower_time).total_seconds()\n",
    "                    interpolated_value = lower_bound + (value_diff * time_diff_missing / time_diff)\n",
    "                    group.at[idx, feature] = interpolated_value\n",
    "        match_data_imputed.loc[group.index, feature] = group[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2def3c8b-81d5-4399-adab-1be7e9295e20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:07:07.126764Z",
     "iopub.status.busy": "2024-12-17T19:07:07.126540Z",
     "iopub.status.idle": "2024-12-17T19:07:07.705394Z",
     "shell.execute_reply": "2024-12-17T19:07:07.704793Z",
     "shell.execute_reply.started": "2024-12-17T19:07:07.126746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rounding after linear interpolation\n",
    "match_data_imputed[list(integer_missing_features)] = match_data_imputed[list(integer_missing_features)].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7928cf6c-0841-4f88-9e33-912bc22dd6cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:07:07.706356Z",
     "iopub.status.busy": "2024-12-17T19:07:07.706172Z",
     "iopub.status.idle": "2024-12-17T19:07:09.740596Z",
     "shell.execute_reply": "2024-12-17T19:07:09.739805Z",
     "shell.execute_reply.started": "2024-12-17T19:07:07.706341Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imputation for Float Type Features\n",
    "for fixture_id, group in match_data.groupby('fixture_id'):\n",
    "    group = group.sort_values('current_time')\n",
    "\n",
    "    for feature in percentage_features:\n",
    "        missing_indices = group[group[feature].isna()].index\n",
    "        for idx in missing_indices:\n",
    "            valid_before = group.loc[:idx, feature].dropna()\n",
    "            lower_bound = valid_before.iloc[-1] if not valid_before.empty else pd.NA\n",
    "            lower_time = group.loc[valid_before.index[-1], 'current_time'] if not valid_before.empty else group.loc[idx, 'current_time']\n",
    "\n",
    "            valid_after = group.loc[idx:, feature].dropna()\n",
    "            upper_bound = valid_after.iloc[0] if not valid_after.empty else pd.NA\n",
    "            upper_time = group.loc[valid_after.index[0], 'current_time'] if not valid_after.empty else group.loc[idx, 'current_time']\n",
    "\n",
    "            if pd.isna(group.at[idx, feature]):\n",
    "                if pd.isna(lower_bound) == True & pd.isna(upper_bound) == True:\n",
    "                    continue\n",
    "                elif pd.isna(lower_bound) == True & pd.isna(upper_bound) == True:\n",
    "                    group.at[idx, feature] = 0\n",
    "                elif pd.isna(lower_bound) and not pd.isna(upper_bound):\n",
    "                    group.at[idx, feature] = upper_bound\n",
    "                elif pd.isna(upper_bound):\n",
    "\n",
    "                    group.at[idx, feature] = lower_bound\n",
    "                else:\n",
    "                    \n",
    "                    time_diff = (upper_time - lower_time).total_seconds()\n",
    "                    value_diff = upper_bound - lower_bound\n",
    "                    time_diff_missing = (group.loc[idx, 'current_time'] - lower_time).total_seconds()\n",
    "                    interpolated_value = lower_bound + (value_diff * time_diff_missing / time_diff)\n",
    "                    group.at[idx, feature] = interpolated_value\n",
    "        match_data_imputed.loc[group.index, feature] = group[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "90495156-65d8-41ca-ae36-0f3d535b34c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:07:09.742615Z",
     "iopub.status.busy": "2024-12-17T19:07:09.742232Z",
     "iopub.status.idle": "2024-12-17T19:07:10.454008Z",
     "shell.execute_reply": "2024-12-17T19:07:10.453265Z",
     "shell.execute_reply.started": "2024-12-17T19:07:09.742595Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imputation for Text Type Features\n",
    "for fixture_id, group in match_data.groupby('fixture_id'):\n",
    "    group = group.sort_values('current_time')\n",
    "\n",
    "    for feature in text_feature:\n",
    "        missing_indices = group[group[feature].isna()].index\n",
    "        for idx in missing_indices:\n",
    "            valid_before = group.loc[:idx, feature].dropna()\n",
    "            lower_bound = valid_before.iloc[-1] if not valid_before.empty else pd.NA\n",
    "            lower_time = group.loc[valid_before.index[-1], 'current_time'] if not valid_before.empty else group.loc[idx, 'current_time']\n",
    "\n",
    "            valid_after = group.loc[idx:, feature].dropna()\n",
    "            upper_bound = valid_after.iloc[0] if not valid_after.empty else pd.NA\n",
    "            upper_time = group.loc[valid_after.index[0], 'current_time'] if not valid_after.empty else group.loc[idx, 'current_time']\n",
    "\n",
    "            if pd.isna(group.at[idx, feature]):\n",
    "                if pd.isna(lower_bound):\n",
    "                    group.at[idx, feature] = \"X\"\n",
    "                elif pd.isna(upper_bound):\n",
    "                    group.at[idx, feature] = lower_bound\n",
    "                else:\n",
    "                    group.at[idx, feature] = \"X\"\n",
    "        match_data_imputed.loc[group.index, feature] = group[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "feba1be2-d0a6-4d0e-9a62-ce39a928c1fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:07:10.455108Z",
     "iopub.status.busy": "2024-12-17T19:07:10.454836Z",
     "iopub.status.idle": "2024-12-17T19:07:13.701523Z",
     "shell.execute_reply": "2024-12-17T19:07:13.700883Z",
     "shell.execute_reply.started": "2024-12-17T19:07:10.455089Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "match_data_imputed.to_csv('match_data_imputed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c2d1cad-2159-4ca9-b002-e83e4325a8fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T15:09:30.960593Z",
     "iopub.status.busy": "2025-01-04T15:09:30.960400Z",
     "iopub.status.idle": "2025-01-04T15:09:31.466855Z",
     "shell.execute_reply": "2025-01-04T15:09:31.466281Z",
     "shell.execute_reply.started": "2025-01-04T15:09:30.960576Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "match_data_imputed = pd.read_csv('match_data_imputed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538d285-cc6b-4599-8738-fedf27b917e2",
   "metadata": {},
   "source": [
    "- Now, dataset is ready to do analysis and training ML models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
